{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Naive Bayes)\t Accuracy (All)=0.79 (842/1070)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Pos)=0.79 (416/527)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Pos)=0.78 (416/533)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Pos)=0.78\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Neg)=0.78 (426/543)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Neg)=0.79 (426/537)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Neg)=0.79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import re, random, math, collections, itertools\n",
    "\n",
    "PRINT_ERRORS=0\n",
    "\n",
    "#------------- Function Definitions ---------------------\n",
    "\n",
    "\n",
    "def readFiles(sentimentDictionary,sentencesTrain,sentencesTest,sentencesNokia):\n",
    "\n",
    "    #reading pre-labeled input and splitting into lines\n",
    "    posSentences = open('rt-polarity.pos', 'r', encoding=\"ISO-8859-1\")\n",
    "    posSentences = re.split(r'\\n', posSentences.read())\n",
    "\n",
    "    negSentences = open('rt-polarity.neg', 'r', encoding=\"ISO-8859-1\")\n",
    "    negSentences = re.split(r'\\n', negSentences.read())\n",
    "\n",
    "    posSentencesNokia = open('nokia-pos.txt', 'r')\n",
    "    posSentencesNokia = re.split(r'\\n', posSentencesNokia.read())\n",
    "\n",
    "    negSentencesNokia = open('nokia-neg.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    negSentencesNokia = re.split(r'\\n', negSentencesNokia.read())\n",
    "\n",
    "    posDictionary = open('positive-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    posWordList = posDictionary.readlines()\n",
    "    posWordList = [line.strip() for line in posWordList if not line.startswith(\";\") and not line == '\\n']\n",
    "    #posWordList = re.findall(r\"[a-z\\-]+\", posDictionary.read())\n",
    "\n",
    "    negDictionary = open('negative-words.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "    negWordList = negDictionary.readlines()\n",
    "    negWordList = [line.strip() for line in negWordList if not line.startswith(\";\") and not line == '\\n']\n",
    "    #negWordList = re.findall(r\"[a-z\\-]+\", negDictionary.read())\n",
    "\n",
    "    for i in posWordList:\n",
    "        sentimentDictionary[i] = 1\n",
    "    for i in negWordList:\n",
    "        sentimentDictionary[i] = -1\n",
    "\n",
    "    #create Training and Test Datsets:\n",
    "    #We want to test on sentences we haven't trained on, to see how well the model generalses to previously unseen sentences\n",
    "\n",
    "  #create 90-10 split of training and test data from movie reviews, with sentiment labels    \n",
    "    for i in posSentences:\n",
    "        if random.randint(1,10)<2:\n",
    "            sentencesTest[i]=\"positive\"\n",
    "        else:\n",
    "            sentencesTrain[i]=\"positive\"\n",
    "\n",
    "    for i in negSentences:\n",
    "        if random.randint(1,10)<2:\n",
    "            sentencesTest[i]=\"negative\"\n",
    "        else:\n",
    "            sentencesTrain[i]=\"negative\"\n",
    "\n",
    "    #create Nokia Datset:\n",
    "    for i in posSentencesNokia:\n",
    "            sentencesNokia[i]=\"positive\"\n",
    "    for i in negSentencesNokia:\n",
    "            sentencesNokia[i]=\"negative\"\n",
    "\n",
    "#----------------------------End of data initialisation ----------------#\n",
    "\n",
    "#calculates p(W|Positive), p(W|Negative) and p(W) for all words in training data\n",
    "def trainBayes(sentencesTrain, pWordPos, pWordNeg, pWord):\n",
    "    posFeatures = [] # [] initialises a list [array]\n",
    "    negFeatures = [] \n",
    "    freqPositive = {} # {} initialises a dictionary [hash function]\n",
    "    freqNegative = {}\n",
    "    dictionary = {}\n",
    "    posWordsTot = 0\n",
    "    negWordsTot = 0\n",
    "    allWordsTot = 0\n",
    "\n",
    "    #iterate through each sentence/sentiment pair in the training data\n",
    "    for sentence, sentiment in sentencesTrain.items():\n",
    "        wordList = re.findall(r\"[\\w']+\", sentence)\n",
    "\n",
    "        #TO DO:\n",
    "        #Populate bigramList (initialised below) by concatenating adjacent words in the sentence.\n",
    "        #You might want to seperate the words by _ for readability, so bigrams such as:\n",
    "        #You_might, might_want, want_to, to_seperate.... \n",
    "\n",
    "        bigramList=wordList.copy() #initialise bigramList\n",
    "        for x in range(len(wordList)-1):\n",
    "           bigramList.append(wordList[x]+\"_\" + wordList[x+1])\n",
    "\n",
    "\n",
    " \n",
    "        #-------------Finish populating bigramList ------------------#\n",
    "        \n",
    "        #TO DO: when you have populated bigramList, uncomment out the line below and , and comment out the unigram line to make use of bigramList rather than wordList\n",
    "        \n",
    "        for word in bigramList: #calculate over bigrams\n",
    "        # for word in wordList: #calculate over unigrams\n",
    "            allWordsTot += 1 # keeps count of total words in dataset\n",
    "            if not (word in dictionary):\n",
    "                dictionary[word] = 1\n",
    "            if sentiment==\"positive\" :\n",
    "                posWordsTot += 1 # keeps count of total words in positive class\n",
    "\n",
    "                #keep count of each word in positive context\n",
    "                if not (word in freqPositive):\n",
    "                    freqPositive[word] = 1\n",
    "                else:\n",
    "                    freqPositive[word] += 1    \n",
    "            else:\n",
    "                negWordsTot+=1# keeps count of total words in negative class\n",
    "                \n",
    "                #keep count of each word in positive context\n",
    "                if not (word in freqNegative):\n",
    "                    freqNegative[word] = 1\n",
    "                else:\n",
    "                    freqNegative[word] += 1\n",
    "\n",
    "    for word in dictionary:\n",
    "        #do some smoothing so that minimum count of a word is 1\n",
    "        if not (word in freqNegative):\n",
    "            freqNegative[word] = 1\n",
    "        if not (word in freqPositive):\n",
    "            freqPositive[word] = 1\n",
    "\n",
    "        # Calculate p(word|positive)\n",
    "        pWordPos[word] = freqPositive[word] / float(posWordsTot)\n",
    "\n",
    "        # Calculate p(word|negative) \n",
    "        pWordNeg[word] = freqNegative[word] / float(negWordsTot)\n",
    "\n",
    "        # Calculate p(word)\n",
    "        pWord[word] = (freqPositive[word] + freqNegative[word]) / float(allWordsTot) \n",
    "\n",
    "#---------------------------End Training ----------------------------------\n",
    "\n",
    "#implement naive bayes algorithm\n",
    "#INPUTS:\n",
    "#  sentencesTest is a dictonary with sentences associated with sentiment \n",
    "#  dataName is a string (used only for printing output)\n",
    "#  pWordPos is dictionary storing p(word|positive) for each word\n",
    "#     i.e., pWordPos[\"apple\"] will return a real value for p(\"apple\"|positive)\n",
    "#  pWordNeg is dictionary storing p(word|negative) for each word\n",
    "#  pWord is dictionary storing p(word)\n",
    "#  pPos is a real number containing the fraction of positive reviews in the dataset\n",
    "def testBayes(sentencesTest, dataName, pWordPos, pWordNeg, pWord,pPos):\n",
    "    pNeg=1-pPos\n",
    "\n",
    "    #These variables will store results (you do not need them)\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalpospred=0\n",
    "    totalneg=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "\n",
    "    #for each sentence, sentiment pair in the dataset\n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        wordList = re.findall(r\"[\\w']+\", sentence)#collect all words\n",
    "\n",
    "        \n",
    "        #TO DO: Exactly what you did in the training function:\n",
    "        #Populate bigramList by concatenating adjacent words in wordList.\n",
    "\n",
    "        bigramList=wordList.copy() #initialise bigramList\n",
    "        for x in range(len(wordList)-1):\n",
    "           bigramList.append(wordList[x]+\"_\" + wordList[x+1])\n",
    "        \n",
    "        \n",
    "\n",
    "#------------------finished populating bigramList--------------\n",
    "        pPosW=pPos\n",
    "        pNegW=pNeg\n",
    "\n",
    "        for word in bigramList: #calculate over bigrams\n",
    "#        for word in wordList: #calculate over unigrams\n",
    "            if word in pWord:\n",
    "                if pWord[word]>0.00000001:\n",
    "                    pPosW *=pWordPos[word]\n",
    "                    pNegW *=pWordNeg[word]\n",
    "\n",
    "        prob=0;            \n",
    "        if pPosW+pNegW >0:\n",
    "            prob=pPosW/float(pPosW+pNegW)\n",
    "\n",
    "\n",
    "        total+=1\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            if prob>0.5:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "                if PRINT_ERRORS:\n",
    "                    print (\"ERROR (pos classed as neg %0.2f):\" %prob + sentence)\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            if prob<=0.5:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    "                if PRINT_ERRORS:\n",
    "                    print (\"ERROR (neg classed as pos %0.2f):\" %prob + sentence)\n",
    " \n",
    "    acc=correct/float(total)\n",
    "    print (dataName + \" Accuracy (All)=%0.2f\" % acc + \" (%d\" % correct + \"/%d\" % total + \")\\n\")\n",
    "\n",
    "    precision_pos=correctpos/float(totalpospred)\n",
    "    recall_pos=correctpos/float(totalpos)\n",
    "    precision_neg=correctneg/float(totalnegpred)\n",
    "    recall_neg=correctneg/float(totalneg)\n",
    "    f_pos=2*precision_pos*recall_pos/(precision_pos+recall_pos);\n",
    "    f_neg=2*precision_neg*recall_neg/(precision_neg+recall_neg);\n",
    "\n",
    "    print (dataName + \" Precision (Pos)=%0.2f\" % precision_pos + \" (%d\" % correctpos + \"/%d\" % totalpospred + \")\")\n",
    "    print (dataName + \" Recall (Pos)=%0.2f\" % recall_pos + \" (%d\" % correctpos + \"/%d\" % totalpos + \")\")\n",
    "    print (dataName + \" F-measure (Pos)=%0.2f\" % f_pos)\n",
    "\n",
    "    print (dataName + \" Precision (Neg)=%0.2f\" % precision_neg + \" (%d\" % correctneg + \"/%d\" % totalnegpred + \")\")\n",
    "    print (dataName + \" Recall (Neg)=%0.2f\" % recall_neg + \" (%d\" % correctneg + \"/%d\" % totalneg + \")\")\n",
    "    print (dataName + \" F-measure (Neg)=%0.2f\" % f_neg + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# This is a simple classifier that uses a sentiment dictionary to classify \n",
    "# a sentence. For each word in the sentence, if the word is in the positive \n",
    "# dictionary, it adds 1, if it is in the negative dictionary, it subtracts 1. \n",
    "# If the final score is above a threshold, it classifies as \"Positive\", \n",
    "# otherwise as \"Negative\"\n",
    "def testDictionary(sentencesTest, dataName, sentimentDictionary, threshold):\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalneg=0\n",
    "    totalpospred=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        Words = re.findall(r\"[\\w']+\", sentence)\n",
    "        score=0\n",
    "        for word in Words:\n",
    "            if word in sentimentDictionary:\n",
    "               score+=sentimentDictionary[word]\n",
    " \n",
    "        total+=1\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            if score>=threshold:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            if score<threshold:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    " \n",
    "    acc=correct/float(total)\n",
    "    print (dataName + \" Accuracy (All)=%0.2f\" % acc + \" (%d\" % correct + \"/%d\" % total + \")\\n\")\n",
    "    precision_pos=correctpos/float(totalpospred)\n",
    "    recall_pos=correctpos/float(totalpos)\n",
    "    precision_neg=correctneg/float(totalnegpred)\n",
    "    recall_neg=correctneg/float(totalneg)\n",
    "    f_pos=2*precision_pos*recall_pos/(precision_pos+recall_pos);\n",
    "    f_neg=2*precision_neg*recall_neg/(precision_neg+recall_neg);\n",
    "\n",
    "\n",
    "    print (dataName + \" Precision (Pos)=%0.2f\" % precision_pos + \" (%d\" % correctpos + \"/%d\" % totalpospred + \")\")\n",
    "    print (dataName + \" Recall (Pos)=%0.2f\" % recall_pos + \" (%d\" % correctpos + \"/%d\" % totalpos + \")\")\n",
    "    print (dataName + \" F-measure (Pos)=%0.2f\" % f_pos)\n",
    "\n",
    "    print (dataName + \" Precision (Neg)=%0.2f\" % precision_neg + \" (%d\" % correctneg + \"/%d\" % totalnegpred + \")\")\n",
    "    print (dataName + \" Recall (Neg)=%0.2f\" % recall_neg + \" (%d\" % correctneg + \"/%d\" % totalneg + \")\")\n",
    "    print (dataName + \" F-measure (Neg)=%0.2f\" % f_neg + \"\\n\")\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#Print out n most useful predictors\n",
    "def mostUseful(pWordPos, pWordNeg, pWord, n):\n",
    "    predictPower={}\n",
    "    for word in pWord:\n",
    "        if pWordNeg[word]<0.0000001:\n",
    "            predictPower[word]=1000000000\n",
    "        else:\n",
    "            predictPower[word]=pWordPos[word] / (pWordPos[word] + pWordNeg[word])\n",
    "            \n",
    "\n",
    "    sortedPower = sorted(predictPower, key=predictPower.get)\n",
    "    head, tail = sortedPower[:n], sortedPower[len(predictPower)-n:]\n",
    "    print (\"NEGATIVE:\")\n",
    "    print (head)\n",
    "    print (\"\\nPOSITIVE:\")\n",
    "    print (tail)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------- Main Script --------------------------\n",
    "\n",
    "\n",
    "sentimentDictionary={} # {} initialises a dictionary [hash function]\n",
    "sentencesTrain={}\n",
    "sentencesTest={}\n",
    "sentencesNokia={}\n",
    "\n",
    "#initialise datasets and dictionaries\n",
    "readFiles(sentimentDictionary,sentencesTrain,sentencesTest,sentencesNokia)\n",
    "\n",
    "pWordPos={} # p(W|Positive)\n",
    "pWordNeg={} # p(W|Negative)\n",
    "pWord={}    # p(W) \n",
    "\n",
    "#build conditional probabilities using training data\n",
    "trainBayes(sentencesTrain, pWordPos, pWordNeg, pWord)\n",
    "\n",
    "#run naive bayes classifier on datasets\n",
    "#print (\"Naive Bayes\")\n",
    "#testBayes(sentencesTrain,  \"Films (Train Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5)\n",
    "testBayes(sentencesTest,  \"Films  (Test Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5)\n",
    "#testBayes(sentencesNokia, \"Nokia   (All Data,  Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.7)\n",
    "\n",
    "\n",
    "\n",
    "#run sentiment dictionary based classifier on datasets\n",
    "# testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, -4)\n",
    "# testDictionary(sentencesTest,  \"Films  (Test Data, Rule-Based)\\t\",  sentimentDictionary, -4)\n",
    "# testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, -3)\n",
    "\n",
    "\n",
    "# print most useful words\n",
    "#mostUseful(pWordPos, pWordNeg, pWord, 50)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDictionary(sentencesTest, dataName, sentimentDictionary, threshold):\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalneg=0\n",
    "    totalpospred=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "    for sentence, sentiment in sentencesTest.items():\n",
    "        Words = re.findall(r\"[\\w']+\", sentence)\n",
    "        score=0\n",
    "        for word in Words:\n",
    "            if word in sentimentDictionary:\n",
    "               score+=sentimentDictionary[word]\n",
    " \n",
    "        total+=1\n",
    "        if sentiment==\"positive\":\n",
    "            totalpos+=1\n",
    "            if score>=threshold:\n",
    "                correct+=1\n",
    "                correctpos+=1\n",
    "                totalpospred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalnegpred+=1\n",
    "        else:\n",
    "            totalneg+=1\n",
    "            if score<threshold:\n",
    "                correct+=1\n",
    "                correctneg+=1\n",
    "                totalnegpred+=1\n",
    "            else:\n",
    "                correct+=0\n",
    "                totalpospred+=1\n",
    " \n",
    "    acc=correct/float(total)\n",
    "    print (dataName + \" Accuracy (All)=%0.2f\" % acc + \" (%d\" % correct + \"/%d\" % total + \")\\n\")\n",
    "    precision_pos=correctpos/float(totalpospred)\n",
    "    recall_pos=correctpos/float(totalpos)\n",
    "    precision_neg=correctneg/float(totalnegpred)\n",
    "    recall_neg=correctneg/float(totalneg)\n",
    "    f_pos=2*precision_pos*recall_pos/(precision_pos+recall_pos);\n",
    "    f_neg=2*precision_neg*recall_neg/(precision_neg+recall_neg);\n",
    "\n",
    "\n",
    "    print (dataName + \" Precision (Pos)=%0.2f\" % precision_pos + \" (%d\" % correctpos + \"/%d\" % totalpospred + \")\")\n",
    "    print (dataName + \" Recall (Pos)=%0.2f\" % recall_pos + \" (%d\" % correctpos + \"/%d\" % totalpos + \")\")\n",
    "    print (dataName + \" F-measure (Pos)=%0.2f\" % f_pos)\n",
    "\n",
    "    print (dataName + \" Precision (Neg)=%0.2f\" % precision_neg + \" (%d\" % correctneg + \"/%d\" % totalnegpred + \")\")\n",
    "    print (dataName + \" Recall (Neg)=%0.2f\" % recall_neg + \" (%d\" % correctneg + \"/%d\" % totalneg + \")\")\n",
    "    print (dataName + \" F-measure (Neg)=%0.2f\" % f_neg + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based)\t Accuracy (All)=0.50 (4826/9593)\n",
      "\n",
      "Films (Train Data, Rule-Based)\t Precision (Pos)=0.50 (4789/9547)\n",
      "Films (Train Data, Rule-Based)\t Recall (Pos)=1.00 (4789/4798)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Pos)=0.67\n",
      "Films (Train Data, Rule-Based)\t Precision (Neg)=0.80 (37/46)\n",
      "Films (Train Data, Rule-Based)\t Recall (Neg)=0.01 (37/4795)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Neg)=0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rule_based(data, labels, sent_dict, threshold=0, sigma=1, trigram_ps=1, trigram_ns=1):\n",
    "    '''\n",
    "      The modified rule-based classification function using trigrams, scoring functions and a \n",
    "      weighed coefficient for the threshold values.\n",
    "      \n",
    "          Args:\n",
    "              data(list): the input sentences\n",
    "              labels(list): the list of annotations\n",
    "              sent_dict(dict): the lookup dictionary\n",
    "              threshold(float): the decision boundary for the sentiments\n",
    "              sigma(float): the weighed coefficient for the threshold\n",
    "              trigram_ps(int): the scoring weight for the positive samples\n",
    "              trigram_ns(int): the scoring weight for the negative samples\n",
    "          Returns:\n",
    "              mean_f_measure(float): the optimization target - Mean F1-Score\n",
    "              np.mean(scores)(float): the mean value of all scored samples\n",
    "    '''\n",
    "    total=0\n",
    "    correct=0\n",
    "    totalpos=0\n",
    "    totalneg=0\n",
    "    totalpospred=0\n",
    "    totalnegpred=0\n",
    "    correctpos=0\n",
    "    correctneg=0\n",
    "    scores = list()\n",
    "    for i in range(len(data)):\n",
    "      wordList = re.findall(r\"[\\w']+\", data[i])\n",
    "      trigramList = wordList.copy()  # initialise trigramList\n",
    "      for x in range(len(wordList) - 2):\n",
    "          trigramList.append(wordList[x] + \"_\" + wordList[x + 1] + \"_\" + wordList[x + 2])\n",
    "      \n",
    "      score = 0\n",
    "      for trigram in trigramList:\n",
    "        words = trigram.split(\"_\")\n",
    "        for word in words:\n",
    "          cur_score = 0\n",
    "          if word in sent_dict:\n",
    "            cur_score+=sent_dict[word]\n",
    "        if cur_score > 0:\n",
    "          score+=trigram_ps\n",
    "        else:\n",
    "          score-=trigram_ns\n",
    "\n",
    "      #print('Total score:', score)\n",
    "      \n",
    "      scores.append(score)\n",
    "\n",
    "      total+=1\n",
    "\n",
    "      if labels[i]=='1':\n",
    "        totalpos+=1\n",
    "        if score>threshold*sigma:\n",
    "          correct+=1\n",
    "          correctpos+=1\n",
    "          totalpospred+=1\n",
    "        else:\n",
    "          totalnegpred+=1\n",
    "          if PRINT_ERRORS:\n",
    "            print (\"ERROR (pos classed as neg %0.2f):\", data[i])\n",
    "      else:\n",
    "        totalneg+=1\n",
    "        if score<=threshold*sigma:\n",
    "            correct+=1\n",
    "            correctneg+=1\n",
    "            totalnegpred+=1\n",
    "        else:\n",
    "            totalpospred+=1\n",
    "            if PRINT_ERRORS:\n",
    "              print (\"ERROR (neg classed as pos %0.2f):\", data[i])\n",
    "\n",
    "    acc=correct/float(total)\n",
    "    print('Sigma:', sigma)\n",
    "    print('Threshold:', threshold)\n",
    "    print('Mean score:', np.mean(scores))\n",
    "    print (\"Accuracy (All)=%0.2f\" % acc + \" (%d\" % correct + \"/%d\" % total + \")\\n\")\n",
    "\n",
    "\n",
    "    # smoothing to avoid division by zero errors\n",
    "    precision_pos=correctpos/round(float(totalpospred) + 0.01, 2)\n",
    "    recall_pos=correctpos/round(float(totalpos) + 0.01, 2)\n",
    "    precision_neg=correctneg/round(float(totalnegpred) + 0.01, 2)\n",
    "    recall_neg=correctneg/round(float(totalneg) + 0.01, 2)\n",
    "    f_pos=2*precision_pos*recall_pos/round(float(precision_pos+recall_pos) + 0.01, 2);\n",
    "    f_neg=2*precision_neg*recall_neg/round(float(precision_neg+recall_neg) + 0.01, 2);\n",
    "\n",
    "    print('Positive scores..')\n",
    "    print(\"Precision (Pos)=%0.2f\" % precision_pos + \" (%d\" % correctpos + \"/%d\" % totalpospred + \")\")\n",
    "    print(\"Recall (Pos)=%0.2f\" % recall_pos + \" (%d\" % correctpos + \"/%d\" % totalpos + \")\")\n",
    "    print(\"F-measure (Pos)=%0.2f\" % f_pos)\n",
    "\n",
    "    print('Negative scores..')\n",
    "    print(\"Precision (Neg)=%0.2f\" % precision_neg + \" (%d\" % correctneg + \"/%d\" % totalnegpred + \")\")\n",
    "    print(\"Recall (Neg)=%0.2f\" % recall_neg + \" (%d\" % correctneg + \"/%d\" % totalneg + \")\")\n",
    "    print(\"F-measure (Neg)=%0.2f\" % f_neg + \"\\n\")\n",
    "\n",
    "    print('Mean scores..')\n",
    "    print(\"Precision (Mean)={:.2f}\".format((precision_pos + precision_neg) / 2))\n",
    "    print(\"Recall (Mean)={:.2f}\".format((recall_pos + recall_neg) / 2))\n",
    "    print(\"F-measure (Mean)={:.2f}\".format((f_pos + f_neg) / 2))\n",
    "    print()\n",
    "\n",
    "    mean_f_measure = (f_pos + f_neg) / 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
